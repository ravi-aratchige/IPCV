{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gun Detection with VGG16\n",
    "\n",
    "This notebook demonstrates how to detecting guns appearing in images or video, using the pre-trained VGG16 deep learning model.\n",
    "\n",
    "To get started, you must have the following requirements installed:\n",
    "\n",
    "1. tensorflow - to preprocess data and work with the VGG16 model\n",
    "2. numpy - to prepare data during testing\n",
    "3. matplotlib - to display images in the Jupyter notebook\n",
    "4. notebook - to run this notebook in a Jupyter server\n",
    "\n",
    "It is recommended to have a virtual environment to isolate these requirements from the rest of your system. This can be done using Python's virtualenv package.\n",
    "\n",
    "First, open a Terminal (Command Prompt on Windows) in the same folder as this notebook and create a virtual environment:\n",
    "\n",
    "```shell\n",
    "python3 -m venv env\n",
    "```\n",
    "\n",
    "Next, activate the virtual environment. For Windows users:\n",
    "\n",
    "```shell\n",
    ".\\env\\Scripts\\activate\n",
    "```\n",
    "\n",
    "For Linux and MacOS users:\n",
    "\n",
    "```shell\n",
    "source env/bin/activate\n",
    "```\n",
    "\n",
    "Now you can safely install the above requirements in your virtual environment:\n",
    "\n",
    "```shell\n",
    "pip install tensorflow numpy matplotlib notebook\n",
    "```\n",
    "\n",
    "After installation is complete, launch the Jupyter server to edit this notebook:\n",
    "\n",
    "```shell\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "The following imports are necessary to work with this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Tensorflow and Keras imports\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.utils import load_img\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in the previous example, we will be performing **transfer learning** with the **VGG16** pre-trained model from **Keras Applications**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "For this scenario, we will be using a custom dataset of gun images, derived from multiple sources on the Internet.\n",
    "\n",
    "The images in the dataset have a **high level of variety and diversity**. This ensures that the model can generalize better to locate and identify guns when operationalized in a real-world scenario.\n",
    "\n",
    "### Exploratory Data Analysis\n",
    "\n",
    "First, we'll inspect how the dataset is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m./data\u001b[0m\n",
      "├── \u001b[01;34mtrain\u001b[0m\n",
      "│   ├── \u001b[01;34mgun\u001b[0m\n",
      "│   └── \u001b[01;34mnogun\u001b[0m\n",
      "└── \u001b[01;34mvalidation\u001b[0m\n",
      "    ├── \u001b[01;34mgun\u001b[0m\n",
      "    └── \u001b[01;34mno gun\u001b[0m\n",
      "\n",
      "6 directories\n"
     ]
    }
   ],
   "source": [
    "!tree \"./data\" -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the dataset has been divided into 2 sub-directories:\n",
    "\n",
    "1. `train` - training data\n",
    "2. `validation` - validation data (which can be used for testing the model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect how many images belong to each class in the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "  gun: 60 images\n",
      "  no-gun: 50 images\n",
      "\n",
      "Validation data:\n",
      "  gun: 45 images\n",
      "  no-gun: 50 images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_images(directory):\n",
    "    return sum(\n",
    "        1 for _ in os.listdir(directory) if _.endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "    )\n",
    "\n",
    "\n",
    "def summarize_data(base_dir):\n",
    "    return {\n",
    "        split: {\n",
    "            category: count_images(os.path.join(base_dir, split, category))\n",
    "            for category in [\"gun\", \"no-gun\"]\n",
    "        }\n",
    "        for split in [\"train\", \"validation\"]\n",
    "    }\n",
    "\n",
    "\n",
    "base_dir = \"./data\"\n",
    "data_summary = summarize_data(base_dir)\n",
    "\n",
    "for split, categories in data_summary.items():\n",
    "    print(f\"{split.capitalize()} data:\")\n",
    "    for category, count in categories.items():\n",
    "        print(f\"  {category}: {count} images\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we have a very limited number of images to work with in our dataset, since we built this dataset from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation\n",
    "\n",
    "When training deep learning models using images, it's always better to use lots of data, especially images with slight variations in them, which can help the model generalize better.\n",
    "\n",
    "But since we have limited data available, we can apply **image augmentation** to expand our dataset.\n",
    "\n",
    "Image augmentation is the process of applying different transformations on our existing images, which results in multiple transformed copies of the same image. Each copy differs from its original image through minor differences created using rotation, flipping, shift etc.\n",
    "\n",
    "Keras allows us to do this using the `ImageDataGenerator` class. In our case, we can augment both the training and testing data with different augmentation criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a data generator object to augment data\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can load the images using the `flow_from_directory()` method in the data generator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 images belonging to 2 classes.\n",
      "Found 19 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the training data via the data generator\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=\"./data/train\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "# Load the validation data via the data generator\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    directory=\"./data/validation\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
