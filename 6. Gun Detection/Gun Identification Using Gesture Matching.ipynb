{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gun Identification Using Gesture Matching\n",
    "\n",
    "This notebook demonstrates how to detect and identify guns appearing in a live video feed, using a custom trained deep learning model.\n",
    "\n",
    "To get started, you must have the following requirements installed:\n",
    "\n",
    "1. `tensorflow` - to load the custom gun detection model\n",
    "2. `numpy` - to perform numerical operations and array manipulations\n",
    "3. `opencv-python` - to capture video from the camera and perform image processing operations\n",
    "4. `notebook` - to run this notebook in a Jupyter server\n",
    "\n",
    "It is recommended to have a virtual environment to isolate these requirements from the rest of your system. This can be done using Python's virtualenv package.\n",
    "\n",
    "First, open a Terminal (Command Prompt on Windows) in the same folder as this notebook and create a virtual environment:\n",
    "\n",
    "```shell\n",
    "python3 -m venv env\n",
    "```\n",
    "\n",
    "Next, activate the virtual environment. For Windows users:\n",
    "\n",
    "```shell\n",
    ".\\env\\Scripts\\activate\n",
    "```\n",
    "\n",
    "For Linux and MacOS users:\n",
    "\n",
    "```shell\n",
    "source env/bin/activate\n",
    "```\n",
    "\n",
    "Now you can safely install the above requirements in your virtual environment:\n",
    "\n",
    "```shell\n",
    "pip install tensorflow numpy opencv-python notebook\n",
    "```\n",
    "\n",
    "After installation is complete, launch the Jupyter server to edit this notebook:\n",
    "\n",
    "```shell\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "The following imports are necessary to work with this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using `opencv-python` to read a live video input from the computer's webcam and perform inference on each frame of the video input, using the custom gun detection model we trained <a href=\"https://github.com/ravi-aratchige/IPCV/blob/main/6.%20Gun%20Detection/Gun%20Detection%20with%20VGG16.ipynb\">previously</a>. The predictions made by this model will be shown in real-time on the webcam's video feed as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before we start the webcam to detect and identify guns, we need to do the following.\n",
    "\n",
    "First, we need to load the saved model from the <a href=\"https://github.com/ravi-aratchige/IPCV/blob/main/6.%20Gun%20Detection/Gun%20Detection%20with%20VGG16.ipynb\">previous notebook</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.engine.sequential.Sequential object at 0x7cef260b5390>\n"
     ]
    }
   ],
   "source": [
    "# Load the saved gun detection modelCheck whether the mask has any non-zero values\n",
    "model = load_model(\"model.h5\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define a **post-processing utility function** to do the following:\n",
    "\n",
    "1. Convert the model's prediction into a **binary mask** using a threshold (in this case, 0.3) - values greater than the threshold wil be converted into 1s and others will be converted in 0s.\n",
    "2. Ensure that the binary mask is a **NumPy array** (of type `uint8`).\n",
    "3. Apply **erosion** to remove small false positives (noise). Erosion removes noise from the mask by shrinking the white regions (1s) i.e. the foreground. This must be done iteratively.\n",
    "4. Apply dilation to restore the size of the eroded mask and adjust the regions affected by the erosion. Dilation restores the size of the previously shrunken regions, which helps recover the eroded regions while keeping the noise reduced. This must also be done iteratively.\n",
    "\n",
    "This function will return the processed mask, or the binary mask as it is if it is empty (i.e. zero values only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_post_processing(prediction, erosion_kernel):\n",
    "    # Convert the prediction to a binary mask using a threshold\n",
    "    binary_mask = (prediction > 0.3).astype(np.uint8)\n",
    "\n",
    "    # Check if the mask is not empty\n",
    "    if np.any(binary_mask):\n",
    "        # Ensure that the binary mask is a NumPy array\n",
    "        binary_mask = np.asarray(binary_mask, dtype=np.uint8)\n",
    "\n",
    "        # Apply erosion to remove small false positives\n",
    "        eroded_mask = cv2.erode(binary_mask, erosion_kernel, iterations=8)\n",
    "\n",
    "        # Apply dilation to restore the size of the image\n",
    "        post_processed_mask = cv2.dilate(eroded_mask, erosion_kernel, iterations=5)\n",
    "\n",
    "        return post_processed_mask\n",
    "    else:\n",
    "        return binary_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the Webcam\n",
    "\n",
    "### VideoCapture Configuration\n",
    "\n",
    "We can now configure and create the VideoCapture object for reading and manipulating the webcam's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set the width of the video capture\n",
    "cap.set(3, 640)\n",
    "# Set the height of the video capture\n",
    "cap.set(4, 480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `cap.set()` has the following parameters:\n",
    "\n",
    "1. `propId` - an integer value assigned to a property of the `VideoCapture` object. `3` is the `propId` for width, while `4` is the `propId` for height.\n",
    "2. The value assigned to these properties (i.e. number of pixels along each axis of the `VideoCapture` object).\n",
    "\n",
    "### Binary Erosion Kernel\n",
    "\n",
    "Next, we initialize the kernel for performing erosion on the binary mask. For this scenario, we will use a 5x5 filter as our kernel, which will move across the binary mask and average out the pixels in the overlapping regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the binary erosion kernel\n",
    "erosion_kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "print(erosion_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Smoothing\n",
    "\n",
    "When working with video input that fluctuates over time, it is important to perform **temporal smoothing**. This is the process of averaging predictions made over a period of time, which helps **reduce short-term fluctuations and noise**, thereby providing a more stable and reliable output.\n",
    "\n",
    "For this, we need to initialize variables to\n",
    "\n",
    "1. Store a history of the most recent predictions made.\n",
    "2. Specify how many predictions will be considered for temporal smoothing (i.e. the maximum number of predictions that will be stored in the predictions history at any moment).\n",
    "\n",
    "For this scenario, we will use the 5 most recent predictions made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty list for storing prediction history\n",
    "prediction_history = []\n",
    "\n",
    "# Initialize maximum number of predictions considered for temporal smoothing\n",
    "history_length_config = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop\n",
    "\n",
    "Finally, we can create the main loop to start and work with the webcam input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Capture a frame from the video feed\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is not empty\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame\")\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame as expected by the VGG16 model\n",
    "    processed_frame = cv2.resize(frame, (224, 224))\n",
    "    img_array = image.img_to_array(processed_frame)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_data = preprocess_input(img_array)\n",
    "\n",
    "    # Perform inference using the model and retrieve the prediction made\n",
    "    prediction = model.predict(img_data)[0][0]\n",
    "\n",
    "    # Append the current prediction to the predictions history\n",
    "    prediction_history.append(prediction)\n",
    "\n",
    "    # Remove any old predictions if the predictions history has exceeded the maximum number of predictions\n",
    "    if len(prediction_history) > history_length_config:\n",
    "        prediction_history = prediction_history[1:]\n",
    "\n",
    "    # Calculate the smoothed prediction using a simple moving average\n",
    "    smoothed_prediction = np.mean(prediction_history)\n",
    "\n",
    "    # Apply post-processing to the smoothed prediction\n",
    "    post_processed_prediction = apply_post_processing(smoothed_prediction)\n",
    "\n",
    "    # Initialize label to be displayed based on the post-processed prediction\n",
    "    prediction_label = (\n",
    "        \"Gun Detected\" if post_processed_prediction > 0.5 else \"No Gun Detected\"\n",
    "    )\n",
    "\n",
    "    # Display the frame with the post-processed prediction\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        f\"Prediction: {prediction_label}\",\n",
    "        (10, 30),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.8,\n",
    "        (255, 255, 255),\n",
    "        2,\n",
    "    )\n",
    "    cv2.imshow(\"Gun Detection\", frame)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    # Break the loop when the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
